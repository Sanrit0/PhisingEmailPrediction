{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "#from nltk.corpus import stopwords\n",
    "#import nltk\n",
    "import re\n",
    "import string\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "import sys\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../utils')\n",
    "import functions as func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_combined</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hpl nom may 25 2001 see attached file hplno 52...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nom actual vols 24 th forwarded sabrae zajac h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>enron actuals march 30 april 1 201 estimated a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hpl nom may 30 2001 see attached file hplno 53...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hpl nom june 1 2001 see attached file hplno 60...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       text_combined  label\n",
       "0  hpl nom may 25 2001 see attached file hplno 52...      0\n",
       "1  nom actual vols 24 th forwarded sabrae zajac h...      0\n",
       "2  enron actuals march 30 april 1 201 estimated a...      0\n",
       "3  hpl nom may 30 2001 see attached file hplno 53...      0\n",
       "4  hpl nom june 1 2001 see attached file hplno 60...      0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_phishing = pd.read_csv('../data/phishing_email.csv')\n",
    "df_phishing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hpl nom may   see attached file hplno  xls hpl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nom actual vols  th forwarded sabrae zajac hou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>enron actuals march  april   estimated actuals...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hpl nom may   see attached file hplno  xls hpl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hpl nom june   see attached file hplno  xls hp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  label\n",
       "0  hpl nom may   see attached file hplno  xls hpl...      0\n",
       "1  nom actual vols  th forwarded sabrae zajac hou...      0\n",
       "2  enron actuals march  april   estimated actuals...      0\n",
       "3  hpl nom may   see attached file hplno  xls hpl...      0\n",
       "4  hpl nom june   see attached file hplno  xls hp...      0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed = func.limpieza_texto(df_phishing)\n",
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras m치s comunes:\n",
      "enron: 53886\n",
      "aug: 47868\n",
      "email: 42919\n",
      "new: 36336\n",
      "ect: 34872\n",
      "submissionid: 32246\n",
      "time: 30149\n",
      "company: 29660\n",
      "information: 27868\n",
      "com: 23763\n",
      "message: 23200\n",
      "list: 22868\n",
      "like: 22464\n",
      "use: 22458\n",
      "added: 21292\n",
      "submission: 21137\n",
      "news: 21086\n",
      "subject: 20797\n",
      "business: 20076\n",
      "sender: 19975\n",
      "total: 19955\n",
      "money: 19753\n",
      "notes: 19692\n",
      "need: 19577\n",
      "know: 19455\n",
      "wed: 18614\n",
      "account: 18602\n",
      "mail: 18098\n",
      "make: 17755\n",
      "virus: 17324\n",
      "university: 17069\n",
      "pm: 17056\n",
      "hou: 16901\n",
      "thu: 16687\n",
      "work: 16393\n",
      "want: 16332\n",
      "wrote: 15811\n",
      "free: 15678\n",
      "send: 15259\n",
      "daily: 14964\n",
      "cnncom: 14558\n",
      "thanks: 14470\n",
      "people: 14256\n",
      "help: 14216\n",
      "said: 14019\n",
      "click: 13921\n",
      "address: 13803\n",
      "contact: 13698\n",
      "data: 13542\n",
      "going: 13205\n",
      "network: 13191\n",
      "receive: 13177\n",
      "sent: 12896\n",
      "best: 12891\n",
      "unsubscribe: 12397\n",
      "way: 12240\n",
      "dont: 12078\n",
      "using: 12075\n",
      "gas: 12039\n",
      "bank: 12019\n",
      "fri: 11833\n",
      "cnn: 11812\n",
      "web: 11704\n",
      "price: 11654\n",
      "day: 11641\n",
      "number: 11569\n",
      "file: 11552\n",
      "group: 11551\n",
      "good: 11237\n",
      "million: 11228\n",
      "order: 11177\n",
      "date: 11145\n",
      "think: 10931\n",
      "deal: 10916\n",
      "energy: 10826\n",
      "security: 10693\n",
      "read: 10686\n",
      "report: 10636\n",
      "cc: 10621\n",
      "research: 10542\n",
      "year: 10398\n",
      "feb: 10318\n",
      "power: 10264\n",
      "mailing: 10248\n",
      "line: 10141\n",
      "available: 10082\n",
      "service: 10046\n",
      "today: 10028\n",
      "software: 9980\n",
      "online: 9848\n",
      "john: 9744\n",
      "site: 9738\n",
      "settings: 9714\n",
      "used: 9610\n",
      "vince: 9557\n",
      "cable: 9477\n",
      "let: 9405\n",
      "years: 9363\n",
      "market: 9282\n",
      "tue: 9265\n"
     ]
    }
   ],
   "source": [
    "func.palabras_mas_comunes(df_processed,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_processed[['body']]\n",
    "y = df_processed['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model naive-bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      7935\n",
      "           1       0.98      0.95      0.96      8563\n",
      "\n",
      "    accuracy                           0.96     16498\n",
      "   macro avg       0.96      0.96      0.96     16498\n",
      "weighted avg       0.96      0.96      0.96     16498\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96     31660\n",
      "           1       0.98      0.95      0.96     34328\n",
      "\n",
      "    accuracy                           0.96     65988\n",
      "   macro avg       0.96      0.96      0.96     65988\n",
      "weighted avg       0.96      0.96      0.96     65988\n",
      "\n",
      "0.9614498727118439\n",
      "0.9620840152755047\n"
     ]
    }
   ],
   "source": [
    "nb_classifier = make_pipeline(TfidfVectorizer(max_features=5500, stop_words='english'),MultinomialNB())\n",
    "nb_classifier.fit(X_train['body'],y_train)\n",
    "\n",
    "# Evaluaci칩n del modelo\n",
    "print(classification_report(y_test, nb_classifier.predict(X_test['body'])))\n",
    "print(classification_report(y_train, nb_classifier.predict(X_train['body'])))\n",
    "\n",
    "print(accuracy_score(y_test, nb_classifier.predict(X_test['body'])))\n",
    "print(accuracy_score(y_train, nb_classifier.predict(X_train['body'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      7935\n",
      "           1       0.98      0.99      0.98      8563\n",
      "\n",
      "    accuracy                           0.98     16498\n",
      "   macro avg       0.98      0.98      0.98     16498\n",
      "weighted avg       0.98      0.98      0.98     16498\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     31660\n",
      "           1       0.99      0.99      0.99     34328\n",
      "\n",
      "    accuracy                           0.99     65988\n",
      "   macro avg       0.99      0.99      0.99     65988\n",
      "weighted avg       0.99      0.99      0.99     65988\n",
      "\n",
      "0.983452539701782\n",
      "0.9923622476813966\n"
     ]
    }
   ],
   "source": [
    "logistic_regression = make_pipeline(TfidfVectorizer(max_features=5500, stop_words='english'),LogisticRegression(C=5.0))\n",
    "logistic_regression.fit(X_train['body'],y_train)\n",
    "\n",
    "# Evaluaci칩n del modelo\n",
    "print(classification_report(y_test, logistic_regression.predict(X_test['body'])))\n",
    "print(classification_report(y_train, logistic_regression.predict(X_train['body'])))\n",
    "\n",
    "print(accuracy_score(y_test, logistic_regression.predict(X_test['body'])))\n",
    "print(accuracy_score(y_train, logistic_regression.predict(X_train['body'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      7935\n",
      "           1       0.98      0.99      0.99      8563\n",
      "\n",
      "    accuracy                           0.99     16498\n",
      "   macro avg       0.99      0.99      0.99     16498\n",
      "weighted avg       0.99      0.99      0.99     16498\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31660\n",
      "           1       1.00      1.00      1.00     34328\n",
      "\n",
      "    accuracy                           1.00     65988\n",
      "   macro avg       1.00      1.00      1.00     65988\n",
      "weighted avg       1.00      1.00      1.00     65988\n",
      "\n",
      "0.9867862771245\n",
      "0.9985148814936049\n"
     ]
    }
   ],
   "source": [
    "xgb_model = make_pipeline(TfidfVectorizer(max_features=5500, stop_words='english'),xgb.XGBClassifier(learning_rate=0.7,n_estimators= 250))\n",
    "xgb_model.fit(X_train['body'],y_train)\n",
    "\n",
    "# Evaluaci칩n del modelo\n",
    "print(classification_report(y_test, xgb_model.predict(X_test['body'])))\n",
    "print(classification_report(y_train, xgb_model.predict(X_train['body'])))\n",
    "\n",
    "print(accuracy_score(y_test, xgb_model.predict(X_test['body'])))\n",
    "print(accuracy_score(y_train, xgb_model.predict(X_train['body'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo en un archivo usando pickle\n",
    "with open('../model/model_NB.pkl', 'wb') as archivo:\n",
    "    pickle.dump(nb_classifier, archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo en un archivo usando pickle\n",
    "with open('../model/model_log_reg.pkl', 'wb') as archivo:\n",
    "    pickle.dump(logistic_regression, archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo en un archivo usando pickle\n",
    "with open('../model/model_xgb.pkl', 'wb') as archivo:\n",
    "    pickle.dump(xgb_model, archivo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
